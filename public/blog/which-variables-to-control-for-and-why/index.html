<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.101.0" />
<title>Which variables to control for, and why | Peder M. Isager</title>


<meta property="twitter:site" content="@peder_isager">
<meta property="twitter:creator" content="@peder_isager">







  
    
  
<meta name="description" content="Personal website of Dr. Peder M. Isager">


<meta property="og:site_name" content="Peder M. Isager">
<meta property="og:title" content="Which variables to control for, and why | Peder M. Isager">
<meta property="og:description" content="Personal website of Dr. Peder M. Isager" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://pedermisager.org/blog/which-variables-to-control-for-and-why/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://pedermisager.org/blog/which-variables-to-control-for-and-why/featured.png" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://pedermisager.org/blog/which-variables-to-control-for-and-why/featured.png" >
    
    
  <meta itemprop="name" content="Which variables to control for, and why">
<meta itemprop="description" content="In this post, we will use a practical example to explore the power of statistical control, explaining why adjusting for the right variables clarifies relationships and why adjusting for the wrong ones can introduce new, serious biases."><meta itemprop="datePublished" content="2026-01-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2026-01-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="813"><meta itemprop="image" content="https://pedermisager.org/blog/which-variables-to-control-for-and-why/featured.png">
<meta itemprop="keywords" content="causal inference,experiment,correlation," />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.51048f8224904aac943a02f6057e4a47960d1d64abe43e43820ed1b3017122c1.css" integrity="sha256-UQSPgiSQSqyUOgL2BX5KR5YNHWSr5D5Dgg7RswFxIsE=" media="screen">
  
  
  <script src="/panelset.min.dca42702d7daf6fd31dc352efd2bcf0e4ac8c05ccaa58d9293f6177462de5d5f.js" type="text/javascript"></script>
  
  
  <script src="/main.min.4bc8a63262b018f2b2f592af2f6db0bf7902219509a8a74e2d6470341130987d.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://pedermisager.org/" title="Home">
      <img src="/img/home_icon.png" class="dib db-l h2 w-auto" alt="Peder M. Isager">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/talk/" title="Talks">Talks</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/files/cv.pdf" title="CV">CV</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="https://pure.tue.nl/ws/portalfiles/portal/200554284/20220524_Isager_hf.pdf" title="Deciding What To Replicate">PhD thesis</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Which variables to control for, and why</h1>
        
        <p class="f6 measure lh-copy mv1">By Peder M Isager</p>
        <p class="f7 db mv0 ttu">January 20, 2026</p>

      

      </header>
      <section class="post-body pt5 pb4">
        


<div id="abstract" class="section level2">
<h2>Abstract</h2>
<p>Causion is a free web app for building causal diagrams (DAGs) and then watching them behave. You can assign values, add noise, generate a dataset, and switch from observation to intervention with the do() operator. Try it now: <a href="https://causion.pedermisager.org/" class="uri">https://causion.pedermisager.org/</a>.</p>
<iframe src="https://causion.pedermisager.org/" width="100%" height="700px" style="border:1px solid #ccc; border-radius:6px;">
</iframe>
<p>In 2019 I took Miguel Hernán’s course “Causal Diagrams: Draw Your Assumptions Before Your Conclusions and fell in love with causal inference—especially causal graph models. These deceptively simple pictures of circles and arrows are almost as easy to formulate as verbal statements about causes, and at the same time they convey a surprising amount of the information contained in a formal causal model. They can be read and appreciated by both mathematicians and applied researchers. In fact, they are a tool by which those two camps of scientists can talk with each other.
I have always felt that causal diagrams (directed acyclic graphs; DAGs) provide the missing link that lets us connect our verbal theories about causes to both formal computational models (structural causal models; SCMs) and statistical hypotheses about data. If you can turn your verbal theory into a DAG, you are well on your way to being able to formalize your theory as a mathematical model. You are also well on your way to generating severe tests of your causal theory, as causal diagrams can be used to generate statistical predictions about data.</p>
<p>The part that is hard to teach
However, it can be tricky to get a mental model of how causality “flows through” a DAG to generate observable data patterns. This is difficult, I think, because to imagine a causal process we cannot think of static images. We need to imagine a dynamic process unfolding over time. When I think about how my causal theory is related to the data I expect to see in the world, I don’t just think about the DAG itself. I imagine the nodes (the little circles) in the DAG varying and changing their values, and then I imagine the influence of one changing variable flowing through the edges (the arrows) and into the other variables downstream in the model. On the paper there is a static diagram, but in my head, a video is playing. I could only really think deeply about causal questions once I learned how to imagine causal diagrams in this way.
What Causion does
To help ourselves—and our students—develop that “video in your head” intuition, I created the web application Causion. Causion lets you build DAGs and explore visually what happens when you manipulate variable values and assumptions.
• Draw and edit DAGs quickly (add variables, connect them with arrows, rearrange the graph).
• Assign and vary variables values easily.
• See causal effects play out live: changes propagate through the graph with an animated “causal flow”.
• Change functional forms and effect strengths in the underlying SCM.
• Add noise or hidden/unmeasured influences to see how they distort what you observe.
• Generate a dataset from the DAG and inspect how scatterplots change as you change the model.
• Switch from observing to intervening using the do() operator (i.e., perform a randomized experiment inside the model).
If that sounds useful, just open it and start dragging sliders: <a href="https://causion.pedermisager.org/" class="uri">https://causion.pedermisager.org/</a>
Try this first (30 seconds)
1. Start with a simple arrow: X → Y. Assign a value to X and watch Y update.
2. Add a confounder Z with Z → X and Z → Y, then generate a dataset and look at the X–Y scatterplot.
3. Now “control for” Z in the plot and see how the relationship between X and Y changes.
4. Finally, intervene: turn on do(X) (randomize X) and compare the scatterplot to the observational one.
Who it is for (and what it is not)
I built Causion for a very practical reason: when you teach DAGs, you often want a live demo where students can predict what will happen and then immediately see whether they were right. Causion lets you build a graph, tweak effect strengths and noise, generate data, and run interventions (do()) while watching the downstream consequences update in real time.
If you want formal diagram analysis (for example, identifying adjustment sets or checking graphical criteria), there are already excellent tools for that, like DAGitty.
Causion is the companion tool for building intuition: “What pattern would this DAG produce?” and “What changes when I intervene?” In other words: it’s less about getting the right answer from a graph, and more about developing the kind of mental model that makes graphs easier to reason with in the first place.
Links
Causion (web app): <a href="https://causion.pedermisager.org/" class="uri">https://causion.pedermisager.org/</a>
Tutorial video: <a href="https://www.youtube.com/watch?v=C3fbtayWWOw" class="uri">https://www.youtube.com/watch?v=C3fbtayWWOw</a>
Source code: <a href="https://github.com/pederisager/causion" class="uri">https://github.com/pederisager/causion</a></p>
<iframe width="100%" height="400" src="https://www.youtube.com/embed/C3fbtayWWOw" title="Causion tutorial video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>A small request
If you try the app and something feels confusing (or if you find a bug), I’d genuinely love to hear about it. My hope is that Causion can make causal ideas easier to teach, easier to learn, and easier to communicate.</p>
</div>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">January 20, 2026</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">4 minute read, 813 words</dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Tags:</dt>
    <dd class="fw5 ml0"> <a href="https://pedermisager.org/tags/causal-inference">causal inference</a>  <a href="https://pedermisager.org/tags/experiment">experiment</a>  <a href="https://pedermisager.org/tags/correlation">correlation</a> </dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
    <dd class="fw5 ml0"><a href="/blog/why-experiments-are-considered-gold-standard-for-answering-causal-questions/">Why experiments are considered gold standard for answering causal questions</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/eight_basic_rules_for_causal_inference/">Eight basic rules for causal inference</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/why_does_correlation_not_equal_causation/">Why does correlation not equal causation?</a></dd>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://pedermisager.org/blog/which-variables-to-control-for-and-why/">Which variables to control for, and why &rarr;</a>
  
</div>

      </footer>
    </article>
    
      
<div class="post-comments pa0 pa4-l mt4">
  
  <script src="https://utteranc.es/client.js"
          repo="apreshill/apero"
          issue-term="pathname"
          theme="boxy-light"
          label="comments :crystal_ball:"
          crossorigin="anonymous"
          async
          type="text/javascript">
  </script>
  
</div>

    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2026 RStudio, Anywhere
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/pederisager" title="github" target="_blank" rel="noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://twitter.com/peder_isager" title="twitter" target="_blank" rel="noopener">
      <i class="fab fa-twitter fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://www.linkedin.com/in/peder-mortvedt-isager-a104966a/" title="linkedin" target="_blank" rel="noopener">
      <i class="fab fa-linkedin fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="http://orcid.org/0000-0002-6922-3590" title="orcid" target="_blank" rel="noopener">
      <i class="ai ai-orcid fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.com/citations?user=_EcbBtYAAAAJ&amp;hl=no&amp;oi=ao" title="graduation-cap" target="_blank" rel="noopener">
      <i class="fas fa-graduation-cap fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://oslonyehoyskole.no/om-oss/ansatte/peder-mortvedt-isager" title="landmark" target="_blank" rel="noopener">
      <i class="fas fa-landmark fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/license/" title="License">License</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
