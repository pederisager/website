<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.101.0" />
<title>Mixed model equivalence test using R and PANGEA | Peder M. Isager</title>


<meta property="twitter:site" content="@peder_isager">
<meta property="twitter:creator" content="@peder_isager">







  
    
  
<meta name="description" content="Personal website of Dr. Peder M. Isager">


<meta property="og:site_name" content="Peder M. Isager">
<meta property="og:title" content="Mixed model equivalence test using R and PANGEA | Peder M. Isager">
<meta property="og:description" content="Personal website of Dr. Peder M. Isager" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://pedermisager.org/blog/mixed_model_equivalence/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://pedermisager.org/blog/mixed_model_equivalence/featured.png" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://pedermisager.org/blog/mixed_model_equivalence/featured.png" >
    
    
  <meta itemprop="name" content="Mixed model equivalence test using R and PANGEA">
<meta itemprop="description" content="How to calculate an equivalence test, and power for an equivalence test, for a fixed effect in a mixed effects model using R and PANGEA."><meta itemprop="datePublished" content="2019-11-25T00:00:00+00:00" />
<meta itemprop="dateModified" content="2019-11-25T00:00:00+00:00" />
<meta itemprop="wordCount" content="2893"><meta itemprop="image" content="https://pedermisager.org/blog/mixed_model_equivalence/featured.png">
<meta itemprop="keywords" content="equivalence,statistics,mixed model," />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.51048f8224904aac943a02f6057e4a47960d1d64abe43e43820ed1b3017122c1.css" integrity="sha256-UQSPgiSQSqyUOgL2BX5KR5YNHWSr5D5Dgg7RswFxIsE=" media="screen">
  
  
  <script src="/panelset.min.dca42702d7daf6fd31dc352efd2bcf0e4ac8c05ccaa58d9293f6177462de5d5f.js" type="text/javascript"></script>
  
  
  <script src="/main.min.a75546a6048e92fe5f1c0f124398a10e6163b026a10a151f920863fa7b8e7874.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://pedermisager.org/" title="Home">
      <img src="/img/home_icon.png" class="dib db-l h2 w-auto" alt="Peder M. Isager">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/talk/" title="Talks">Talks</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/files/cv.pdf" title="CV">CV</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="https://pure.tue.nl/ws/portalfiles/portal/200554284/20220524_Isager_hf.pdf" title="Deciding What To Replicate">PhD thesis</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Mixed model equivalence test using R and PANGEA</h1>
        
        <p class="f6 measure lh-copy mv1">By Peder M. Isager</p>
        <p class="f7 db mv0 ttu">November 25, 2019</p>

      

      </header>
      <section class="post-body pt5 pb4">
        


<p><em>How to calculate an equivalence test, and power for an equivalence test, for a fixed effect in a mixed effects model using R and PANGEA.</em></p>
<div id="introduction-to-a-two-part-problem" class="section level2">
<h2>Introduction to a two-part problem</h2>
<p>Calculating equivalence test (TOST) power for fixed effects in a mixed model can be compartmentalized into two independent problems. First, we need a method for calculating TOST power from the non-centrality parameters (ncp) and degrees of freedom (df) of a test. TOSTER <span class="citation">(<a href="#ref-Lakens2017d" role="doc-biblioref">Lakens 2017</a>)</span> does not currently take this approach when calculating power, but it is straight-forward to recast the calculations in terms of ncps and dfs based on formulas provided in the literature.</p>
<p>Once a method for calculating power based on ncp and df has been identified, the problem of calculating power reduces to a problem of identifying an appropriate ncp and df for the expected mixed model effect. This is by no means trivial, as calculations of ncp and df can become quite complicated with multiple random factors in the model <span class="citation">(<a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a>)</span>. Fortunately, the free and open source power calculator PANGEA can be used to extract the ncp and df for a wide array of mixed model designs <span class="citation">(<a href="#ref-westfall2015pangea" role="doc-biblioref">Westfall 2015</a>)</span>. We can use PANGEA to extract the ncp and df for both tests of a TOST procedure, given some equivalence bounds. From there, we can simply plug these values into our formula for calculating power since, at this point, power for mixed and fixed designs are calculated in the same way.</p>
</div>
<div id="part-1-calculating-power-for-a-one-sample-equivalence-test-using-noncentrality-parameters-ncp" class="section level2">
<h2>Part 1: Calculating power for a (one-sample) equivalence test using noncentrality parameters (ncp)</h2>
<p>Say we want to calculate the power of an equivalence test for a one-sample t-test with the following parameters:</p>
<pre class="r"><code>es &lt;- 0            # Assumed effect size (alternative hypothesis). Set to 0 to assume that there is no true effect.
s &lt;- 1             # Standard deviation. When set to 1, &quot;ës&quot; contain values on Cohen&#39;s d scale.
n &lt;- 100           # Number of subjects. 
se &lt;- (s/sqrt(n))  # Standard error.
df &lt;- n-1          # degrees of freedom.
alpha &lt;- 0.05      # Type I error rate.</code></pre>
<p>If we wanted to calculate power for a traditional two-sided null hypothesis test using noncentrality parameters and degrees of freedom, we could set up the analysis in the following way (from <a href="https://www.cyclismo.org/tutorial/R/power.html" class="uri">https://www.cyclismo.org/tutorial/R/power.html</a>):</p>
<pre class="r"><code>ncp &lt;- es/se                    # notice that the ncp is just a t value - the t value on which we would expect the t-distribution to be centered, given some difference between the groups. If the npc is 0, we assume a central t-distribution. 
crit_t &lt;- qt(1-alpha/2, df=df)  # alpha/2 denotes a two-sided t test, and is the same as specifying alpha=0.025. 

typeII &lt;- pt(crit_t, df=df, ncp=ncp) - pt(-crit_t, df=df, ncp=ncp)   # The type II error of the test.
power &lt;- 1-(pt(crit_t,df=df,ncp=ncp) - pt(-crit_t, df=df, ncp=ncp))  # The power of the test, which equals 1-typeII
paste(&quot;Power =&quot;, power)</code></pre>
<pre><code>## [1] &quot;Power = 0.05&quot;</code></pre>
<p>We can verify that this calculation is correct by comparing it against the results of the <code>power.t.test()</code> function in base R and the <code>pwr.t.test</code> function in the “pwr” package. When <code>es = 0</code>, power will reduce to the type I error rate (in reality we have no power, since there is no true effect to detect). You can change the value of <code>es</code> to see that the calculations are identical regardless of effect size.</p>
<pre class="r"><code>power.t.test(n = n, delta = es, sd = s, sig.level = alpha, type = &quot;one&quot;, alternative = &quot;two.sided&quot;, strict = TRUE)  # The strict argument must be set to TRUE for this test to calculate power correctly for the two-sample case.</code></pre>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 100
##           delta = 0
##              sd = 1
##       sig.level = 0.05
##           power = 0.05
##     alternative = two.sided</code></pre>
<pre class="r"><code>pwr::pwr.t.test(n = n, d = es/s, sig.level = alpha, type = &quot;one&quot;, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 100
##               d = 0
##       sig.level = 0.05
##           power = 0.05
##     alternative = two.sided</code></pre>
<p>Now let us extend the use of noncentrality parameters to the case of the two-one-sided-tests (TOST) used for equivalence testing. First we must decide on a smallest effect size of interest (SESOI) to use as bounds for the equivalence test. Let us assume that we consider a group difference of 0.3, in either direction, to be the smallest effect we care about. Because the population standard deviation <code>s</code> is 1, we can choose whether to think of the group difference as a raw difference or a difference in Cohen’s <em>d</em>. The two will the same for this example since <code>d = es/s</code>, and s is 1, so <code>d = es/1 = es</code>.</p>
<pre class="r"><code>bound_l &lt;- -0.3  # Smallest negative effect size of interest (TOST null hypothesis)
bound_u &lt;-  0.3  # Smallest positive effect size of interest (TOST null hypothesis)</code></pre>
<p>Having defined our bounds, we can calculate the ncp for the tests against the upper and lower bounds (the assumed effect size is the difference between the assumed (null) effect and the bound). We then use these npc values to calculate the power for the equivalence test <span class="citation">(<a href="#ref-Chow2008" role="doc-biblioref">Chow, Shao, and Wang 2008, p55, 3rd</a> equation)</span>:</p>
<pre class="r"><code>ncp_l &lt;- (es + bound_l) / se 
ncp_u &lt;- (es + bound_u) / se
crit_t &lt;- qt(alpha, df, lower.tail = FALSE)

power &lt;- ifelse(1 - pt(-crit_t, df, ncp_l, lower.tail = FALSE) - pt(crit_t, df, ncp_u, lower.tail = TRUE) &gt; 0,
                1 - pt(-crit_t, df, ncp_l, lower.tail = FALSE) - pt(crit_t, df, ncp_u, lower.tail = TRUE),
                0)  # Derived from Chow, Shao &amp; Wang (2008), page 55, third formula, slightly tweaked to allow different SESOI for upper and lower bound.

paste(&quot;Power =&quot;, power)</code></pre>
<pre><code>## [1] &quot;Power = 0.817975007468883&quot;</code></pre>
<p>We can verify our calculations against the results from the <code>power_t_TOST()</code> function in TOSTER. The results should be identical.</p>
<pre class="r"><code>TOSTER::power_t_TOST(alpha = alpha, n = n, low_eqbound = bound_l, high_eqbound = bound_u, type = &quot;one-sided&quot;)</code></pre>
<pre><code>## 
##       TOST power calculation 
## 
##           power = 0.817975
##            beta = 0.182025
##           alpha = 0.05
##               n = 100
##           delta = 0
##              sd = 1
##          bounds = -0.3, 0.3</code></pre>
</div>
<div id="part-2-extending-the-ncp-approach-to-mixed-designs-using-pangea" class="section level2">
<h2>Part 2: Extending the ncp approach to mixed designs using PANGEA</h2>
<p>Having resolved the issue of how to calculate equivalence test power from the degrees of freedom and noncentrality parameter, we must now turn to the issue of how to calculate noncentrality parameters in the first place. The ncp equals the effect size divided by the effect standard error, or:</p>
<p><span class="math inline">\(ncp=\frac{\theta}{\sigma/\sqrt{n}}\)</span></p>
<p>Where <span class="math inline">\(\theta\)</span> is the assumed effect size in the population, <span class="math inline">\(\sigma\)</span> is the assumed standard deviation in the population, and <span class="math inline">\(n\)</span> is the number of observations.</p>
<p>For simple designs, this formula is easily calculated (just calculate the <em>t</em>-value of the assumed effect). However, for mixed model desigs, the details of the calculation becomes more complicated due to the partitioning of variance among the random variables and their interactions. In practice, the details of the calculation will depend on the specifics of the design and the number of random variables involved <span class="citation">(<a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a>; <a href="#ref-westfall2015pangea" role="doc-biblioref">Westfall 2015</a>)</span>. For example, the ncp for a two-group fully crossed design, where the effect is assumed to vary randomly across participants and stimuli, is defined as:</p>
<p><span class="math inline">\(npc=\frac{d}{2\sqrt{\frac{V_P\times_C}{p}+\frac{V_S\times_C}{q}+\frac{V_E}{2pq}}}\)</span></p>
<p><span class="citation">(see Table A1 in <a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a> for a definition of formula parameters)</span>. Fortunately, the Shiny application PANGEA <span class="citation">(<a href="#ref-westfall2015pangea" role="doc-biblioref">Westfall 2015</a>)</span> can take care of the ncp calculation for us. All we need to do is to specify the planned design, the random variables, and make some assumptions about the variance partitioning coefficients <span class="citation">(<span>“VCP,”</span> <a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a>)</span> involved. PANGEA will then return the ncp and Welch-Satterthwaite approximated degrees of freedom. It will also return the power for a selected fixed effect given the specified design. The power is based on a <em>t</em>-test for the effect. This approach can in principle be extended to tests of any fixed linear contrast <span class="citation">(<a href="#ref-westfall2015pangea" role="doc-biblioref">Westfall 2015</a>)</span>.</p>
<p>In order to plug the information from PANGEA into the equivalence test power formula, we need to perform two tests in PANGEA; one for the test against each of the bounds we have defined. For example, if we define d=-0.5 and d=0.5 as our lower and upper bound, respectively, then we need to compute the ncp in PANGEA for one test where “Effect size (d)” is set to <code>theta + bound_l</code>, and for another test where “Effect size (d)” is set to <code>theta + bound_u</code>. We can then simply plug the ncp and df reported by PANGEA into the power calculation defined in part 1 to get equivalence test power for a fixed effect in our mixed model design.</p>
<p>As an example of how to excecute the whole procedure, suppose we would like to calculate power for the fully crossed design mentioned above. First, let us assume the following input parameters for the tests <span class="citation">(see the appendix of <a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a> for detailes on how Cohen’s d is defined in this design)</span>:</p>
<pre class="r"><code>d &lt;- 0    # assumed effect size in units of Cohen&#39;s d, using a joint standard deviation over all variance components.
bound_l &lt;- -0.3  # Smallest negative effect size of interest in same units as d (null hypothesis)
bound_u &lt;-  0.3  # Smallest positive effect size of interest in same units as d (null hypothesis)
p &lt;- 100  # number of subjects
q &lt;- 100  # number of stimuli
alpha &lt;- 0.05  # significance threshold
## Assumed variance component ratios, following default partition procedure described in Westfall (2014, 2015):
Ve &lt;- 0.3
Vpxc &lt;- 0.1
Vsxc &lt;- 0.1</code></pre>
<p>We could obtain the ncp and df via the following formulas <span class="citation">(<a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd 2014</a>)</span>:</p>
<pre class="r"><code>se &lt;- 2 * sqrt( Vpxc/p + Vsxc/q + Ve/(2*p*q) )  # standard error of the estimate (information about standard deviation contained within d)
ncp &lt;- d / se  # calculate t value/non-centrality parameter for the assumed effect size
df &lt;- (q*Vpxc + p*Vsxc + Ve)^2 / ( (q*Vpxc+Ve)^2/(p-1) + (p*Vsxc+Ve)^2/(q-1) + Ve^2/((p-1)*(q-1)))  # Welch-Satterthwaite approximation


ncp_l &lt;- (d + bound_l) / se  # calculate t value/non-centrality parameter corresponding to the smallest negative effect size of interest
ncp_u &lt;- (d + bound_u) / se  # calculate t value/non-centrality parameter corresponding to the smallest positive effect size of interest</code></pre>
<p>We could also extract these values from PANGEA. In either case, we then take the df and ncp and calculate power in exactly the same way as we would for the simple t-test*.</p>
<pre class="r"><code>crit_t &lt;- qt(alpha, df, lower.tail = FALSE)
power &lt;- ifelse(1 - pt(-crit_t, df, ncp_l, lower.tail = FALSE) - pt(crit_t, df, ncp_u, lower.tail = TRUE) &gt; 0,
                1 - pt(-crit_t, df, ncp_l, lower.tail = FALSE) - pt(crit_t, df, ncp_u, lower.tail = TRUE),
                0)  # Derived from Chow, Wang $ Chao (2008), page 55, third formula, slightly tweaked to allow different SESOI for upper and lower bound. 
power</code></pre>
<pre><code>## [1] 0.9080016</code></pre>
<p><span style="color:red">*<strong>OBS!</strong> Note that the ncp calculated using the formula derived from <span class="citation"><a href="#ref-Westfall2014" role="doc-biblioref">Westfall, Kenny, and Judd</a> (<a href="#ref-Westfall2014" role="doc-biblioref">2014</a>)</span> does not perfectly correspond to the ncp calculated by PANGEA! The numbers <em>should</em> be identical. Neither I nor Jake Westfall is currently sure what the source of this divergence is. I have done some informal testing which suggests that the two methods seem to produce very similar numbers, which means that either methold will probably be quite accurate for practical purposes. However, I cannot guarantee that there are not some conditions where the two methods might produce very different numbers</span>.</p>
</div>
<div id="calculating-an-equivalence-test-for-an-estimated-fixed-effect-in-mixed-model" class="section level1">
<h1>Calculating an equivalence test for an estimated fixed effect in mixed model</h1>
<p>Having derived a solution for how to calculate the power of a mixed model fixed effect equivalence test, we may reasonably ask how we would calculate the actual equivalence test once the data are in. A relatively straight-forward approach is to fit the model using the <code>lme4</code> package in R. From this model we can extract the effect size estimate and Welch-Satterthwaite degrees of freedom for the fixed effect of interest. We then calculate TOST in the same way as we would for a simple t-test with no random effects assumed.</p>
<p>Suppose we have the following dataset (counter-balanced design, no true effect), and a SESOI of raw effect size = 0.5:</p>
<pre class="r"><code>set.seed(3)
# Dataset
data &lt;- data.frame(&quot;participant&quot; = as.factor(rep(1:10, each = 10)),
                   &quot;condition&quot; = as.factor(rep(c(0,1,1,0), 5, each = 5)),
                   &quot;stimulus&quot; = as.factor(rep(1:10, 10)),
                   &quot;response&quot; = rnorm(100))
summary(data)</code></pre>
<pre><code>##   participant condition    stimulus     response       
##  1      :10   0:50      1      :10   Min.   :-2.26540  
##  2      :10   1:50      2      :10   1st Qu.:-0.72254  
##  3      :10             3      :10   Median : 0.03419  
##  4      :10             4      :10   Mean   : 0.01104  
##  5      :10             5      :10   3rd Qu.: 0.73927  
##  6      :10             6      :10   Max.   : 1.73554  
##  (Other):40             (Other):40</code></pre>
<pre class="r"><code># Equivalence bounds
bound_u &lt;-  0.5  # Upper equivalence bound
bound_l &lt;- -0.5  # Lower equivalence bound</code></pre>
<p>Now we fit a linear mixed model to the data, assuming a fixed effect of condition, and random effects of participants and stimuli:</p>
<pre class="r"><code>library(lme4)
library(lmerTest)</code></pre>
<pre class="r"><code>fm &lt;- lmer(response ~ condition + 
             (1 + condition | participant) + 
             (1 + condition | stimulus), 
           data)</code></pre>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<pre class="r"><code>summary(fm)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: 
## response ~ condition + (1 + condition | participant) + (1 + condition |  
##     stimulus)
##    Data: data
## 
## REML criterion at convergence: 252.8
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.38943 -0.77473  0.01916  0.77860  1.77988 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev. Corr 
##  participant (Intercept) 0.09554  0.3091        
##              condition1  0.17918  0.4233   -0.90
##  stimulus    (Intercept) 0.00134  0.0366        
##              condition1  0.02356  0.1535   1.00 
##  Residual                0.64767  0.8048        
## Number of obs: 100, groups:  participant, 10; stimulus, 10
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)
## (Intercept)   0.1316     0.1505  8.9493   0.874    0.405
## condition1   -0.2411     0.2149  8.6014  -1.122    0.292
## 
## Correlation of Fixed Effects:
##            (Intr)
## condition1 -0.749
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<p>The <code>lmerTest</code> package adds a t-test with Welch-Satterthwaite approximation to df for each fixed effect in our model (in this case, intercept and condition). This is the same t-test approach that PANGEA calculates power for <span class="citation">(<a href="#ref-westfall2015pangea" role="doc-biblioref">Westfall 2015</a>)</span>. It is directly calculated from the estimated effect and std.error provided in the basic <code>lmer</code> model.</p>
<p>There are at least three ways to calculate an equivalence test from the data provided in this model. First, we can use the <code>contest1D</code> functions of the lmerTest package to perform tests centered on the lower and upper equivalence bound, using the <code>rhs</code> option:</p>
<pre class="r"><code>lower &lt;- contest1D(fm, c(0, 1), confint=TRUE, rhs=bound_l) # get t value for test against lower bound
upper &lt;- contest1D(fm, c(0, 1), confint=TRUE, rhs=bound_u) # get t value for test against upper bound
lower</code></pre>
<pre><code>##     Estimate Std. Error       df  t value      lower     upper  Pr(&gt;|t|)
## 1 -0.2410955   0.214897 8.601367 1.204784 -0.7306825 0.2484914 0.2603875</code></pre>
<pre class="r"><code>upper</code></pre>
<pre><code>##     Estimate Std. Error       df   t value      lower     upper    Pr(&gt;|t|)
## 1 -0.2410955   0.214897 8.601367 -3.448608 -0.7306825 0.2484914 0.007803962</code></pre>
<p>The test provided by <code>contest1D</code> is two-sided, but we can easily recalculate the required one-sided tests from the t-values provided (or simply divide by 2 the p-values provided by <code>contest1D</code>):</p>
<pre class="r"><code>pt(lower$`t value`, lower$df, lower.tail = FALSE)  # test against lower bound</code></pre>
<pre><code>## [1] 0.1301938</code></pre>
<pre class="r"><code>lower$`Pr(&gt;|t|)`/2  # test against lower bound</code></pre>
<pre><code>## [1] 0.1301938</code></pre>
<pre class="r"><code>pt(upper$`t value`, upper$df, lower.tail = TRUE)  # test against upper bound</code></pre>
<pre><code>## [1] 0.003901981</code></pre>
<pre class="r"><code>upper$`Pr(&gt;|t|)`/2  # test against upper bound</code></pre>
<pre><code>## [1] 0.003901981</code></pre>
<p>If both these tests are significant, so is the test for equivalence. In this case, the test against the lower bound is not significant, which means that we cannot reject that the true value is not equal to or more extreme than <code>bound_l</code>, which means that we failed to obtain an equivalent result.</p>
<p>Instead of relying on <code>lmerTest</code>, we can also calculate the equivalence test directly from the estimated effects, standard error and degrees of freedom in the basic <code>lme4</code> model. All we need to do is subtract each bound from the effect size when calculating the t value:</p>
<pre class="r"><code># Reproduce test without the use of rhs, by subtracting the bound t values from the estimated effect
pt((lower$Estimate-bound_l)/lower$`Std. Error`, lower$df, lower.tail = FALSE)  # test against lower bound </code></pre>
<pre><code>## [1] 0.1301938</code></pre>
<pre class="r"><code>pt((upper$Estimate-bound_u)/upper$`Std. Error`, upper$df, lower.tail = TRUE)  # test against upper bound</code></pre>
<pre><code>## [1] 0.003901981</code></pre>
<p>The result should be identical to the solution provided by lmerTest.</p>
<p>Finally, we can compare our upper and lower equivalence bound to the 90% (or alpha*2 more generally) confidence interval of an effect estimate, again using <code>contest1D</code>:</p>
<pre class="r"><code>contest1D(fm, c(0, 1), confint=TRUE, rhs=bound_l, level = 0.9)</code></pre>
<pre><code>##     Estimate Std. Error       df  t value      lower     upper  Pr(&gt;|t|)
## 1 -0.2410955   0.214897 8.601367 1.204784 -0.6371148 0.1549237 0.2603875</code></pre>
<p>If the <code>lower</code> and <code>upper</code> bounds of the 90% confidence interval falls within the boundry specified by our SESOI, the equivalence test is significant.</p>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Chow2008" class="csl-entry">
Chow, Shein-Chung, Jun Shao, and Hansheng Wang, eds. 2008. <em>Sample Size Calculations in Clinical Research</em>. 2nd ed. Chapman &amp; <span>Hall</span>/<span>CRC</span> Biostatistics Series 20. <span>Boca Raton</span>: <span>Chapman &amp; Hall/CRC</span>.
</div>
<div id="ref-Lakens2017d" class="csl-entry">
Lakens, Daniel. 2017. <span>“Equivalence <span>Testing With TOSTER</span>.”</span> <em>APS Observer</em> 30 (3).
</div>
<div id="ref-westfall2015pangea" class="csl-entry">
Westfall, Jacob. 2015. <span>“<span>PANGEA</span>: <span>Power</span> Analysis for General Anova Designs.”</span> <em>Unpublished Manuscript. Available at Http://Jakewestfall.org/Publications/Pangea.pdf</em>.
</div>
<div id="ref-Westfall2014" class="csl-entry">
Westfall, Jacob, David A. Kenny, and Charles M. Judd. 2014. <span>“Statistical Power and Optimal Design in Experiments in Which Samples of Participants Respond to Samples of Stimuli.”</span> <em>Journal of Experimental Psychology: General</em> 143 (5): 2020–45. <a href="https://doi.org/10.1037/xge0000014">https://doi.org/10.1037/xge0000014</a>.
</div>
</div>
</div>
</div>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">November 25, 2019</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">14 minute read, 2893 words</dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Tags:</dt>
    <dd class="fw5 ml0"> <a href="https://pedermisager.org/tags/equivalence">equivalence</a>  <a href="https://pedermisager.org/tags/statistics">statistics</a>  <a href="https://pedermisager.org/tags/mixed-model">mixed model</a> </dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="https://pedermisager.org/blog/meta-research-at-the-psa/">&larr; Meta-research at the Psychological Science Accelerator</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://pedermisager.org/blog/psa-theory-committee/">Proposing a theory committee at the Psychological Science Accelerator &rarr;</a>
  
</div>

      </footer>
    </article>
    
      
<div class="post-comments pa0 pa4-l mt4">
  
  <script src="https://utteranc.es/client.js"
          repo="apreshill/apero"
          issue-term="pathname"
          theme="boxy-light"
          label="comments :crystal_ball:"
          crossorigin="anonymous"
          async
          type="text/javascript">
  </script>
  
</div>

    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2023 RStudio, Anywhere
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/pederisager" title="github" target="_blank" rel="noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://twitter.com/peder_isager" title="twitter" target="_blank" rel="noopener">
      <i class="fab fa-twitter fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://www.linkedin.com/in/peder-mortvedt-isager-a104966a/" title="linkedin" target="_blank" rel="noopener">
      <i class="fab fa-linkedin fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="http://orcid.org/0000-0002-6922-3590" title="orcid" target="_blank" rel="noopener">
      <i class="ai ai-orcid fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.com/citations?user=_EcbBtYAAAAJ&amp;hl=no&amp;oi=ao" title="graduation-cap" target="_blank" rel="noopener">
      <i class="fas fa-graduation-cap fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://oslonyehoyskole.no/om-oss/ansatte/peder-mortvedt-isager" title="landmark" target="_blank" rel="noopener">
      <i class="fas fa-landmark fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/license/" title="License">License</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
